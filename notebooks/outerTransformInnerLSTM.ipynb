{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea3993a-56f2-49b5-ab53-d0c7fba34a5e",
   "metadata": {},
   "source": [
    "# Encoder-Transformer-Decoder\n",
    "Encoder and decoder taken from 'e2e_enc_dec.py'\n",
    "Transformer framework from 'TransformerEncDec-Unpolished.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adafcb4-b06d-4d9b-8a70-53cce04fcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!usr/bin/python3\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from keras.layers import Flatten, Dense, Reshape\n",
    "\n",
    "import numpy as np\n",
    "import pickle, random, string\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166900fa-cf8e-4b1d-adc2-22b9dd94c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.OneDeviceStrategy('cpu:0') # Chooses what to run on: CPU or GPU - Can use GPU:0, GPU:1, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7b339-2a68-4dea-b497-aa13354d2efa",
   "metadata": {},
   "source": [
    "# Prepare input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01968f05-8426-4d73-9e69-46183dfb901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('../data/len5_10000-train.txt')#corpus = np.loadtxt(sys.argv[1], dtype=object)\n",
    "corpus = np.loadtxt(corpus, dtype=object)\n",
    "\n",
    "corpus_test = open('../data/len5_10000-test.txt')#corpus = np.loadtxt(sys.argv[1], dtype=object)\n",
    "corpus_test = np.loadtxt(corpus_test, dtype=object)\n",
    "\n",
    "trainingSet = open('../data/SG-10-train.txt')\n",
    "testingSet  = open('../data/SG-10-test.txt')\n",
    "\n",
    "trainingSet = np.loadtxt(trainingSet, dtype=str)\n",
    "testingSet  = np.loadtxt(testingSet, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce5e67-0d8c-48bc-bd3f-b4bde97c997f",
   "metadata": {},
   "source": [
    "Length of sequences to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d563555-038a-4f8a-8402-ee6b5a557943",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10\n",
    "padded_length = 20\n",
    "\n",
    "# Note we are making these the same, but they don't -have- to be!\n",
    "input_length = padded_length\n",
    "output_length = padded_length\n",
    "\n",
    "# Vocabulary sizes...\n",
    "encoder_vocab_size = 30 # blank, a, b, c, ... j (bc/SG-10)\n",
    "decoder_vocab_size = 30 # blank, a, b, c, ... j, start, stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989fd8d7-1397-4267-bb1e-30873916d3ee",
   "metadata": {},
   "source": [
    "Encode the words/letters using integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccbb045-8027-4bb9-bf1e-f1f639cc27ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roles\n",
    "#training_roles = np.loadtxt(trainingSet, dtype=object) # sys.argv[2]\n",
    "#testing_roles  = np.loadtxt(testingSet, dtype=object)  # sys.argv[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49ebc2-0998-432e-bb2d-e132077f76c8",
   "metadata": {},
   "source": [
    "Define a mapping function from characters to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9d4593-71a0-429d-bc37-b71215f1f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_to_int(char_array):\n",
    "    # --- Create a dictionary for all the letters & start/stops ---\n",
    "    alphabet = np.array([i for i in range(1, 31)]) # All letters plus STARTSENTENCE, STOPSENTENCE, start, stop\n",
    "    mapping = dict()\n",
    "    for i in range(len(alphabet) - 4):\n",
    "        mapping[chr(ord('a') + i)] = alphabet[i]\n",
    "\n",
    "    mapping['start'] = alphabet[26]\n",
    "    mapping['stop']  = alphabet[27]\n",
    "    mapping['STARTSETNENCE'] = alphabet[28]\n",
    "    mapping['STOPSENTENCE']  = alphabet[29]\n",
    "    \n",
    "    # --- Map the characters in the input array to integers ---\n",
    "    x_input = char_array\n",
    "    x_input = [list(i) for i in x_input]\n",
    "    X = []\n",
    "    for word in x_input:\n",
    "        X.append([mapping[sym] for sym in word])\n",
    "        #print(\"word=\", word)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    \n",
    "    # --- Create Y, preY, postY ---\n",
    "    Y = []\n",
    "    for word in X:\n",
    "        Y.append(np.concatenate((np.array([27]), word, np.array([28])), axis=0))\n",
    "\n",
    "    Y = np.array(Y)\n",
    "    preY  = Y[:, :-1]\n",
    "    postY = Y[:, 1:]\n",
    "    \n",
    "    return X, Y, preY, postY, mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c784be-7c5e-4374-bb92-b244bfb46208",
   "metadata": {},
   "source": [
    "Define reverse map function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebcc97c6-1a29-43ce-9de1-9539dcd21451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_letter(encoding, mapping):\n",
    "    enc_shape = encoding.shape\n",
    "    \n",
    "    flat_encoding = encoding.flatten() # Flatten array to just one dimension\n",
    "    \n",
    "    # list out keys and values separately\n",
    "    key_list = list(mapping.keys())\n",
    "    val_list = list(mapping.values())\n",
    "\n",
    "    integers = []\n",
    "    for letter in flat_encoding:\n",
    "        integers.append(key_list[val_list.index(letter)])\n",
    "        \n",
    "    integers = np.array(integers)\n",
    "    integers = np.reshape(integers, enc_shape)\n",
    "    return integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b44c86-3b26-4679-8a5d-a678d5fed98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf72f3-26f0-44b0-a0d7-898436aaff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, preY, postY, mapping = letter_to_int(corpus)\n",
    "\n",
    "print(len(mapping))\n",
    "\n",
    "print(int_to_letter(Y[0:5], mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bff8998-762b-423f-98f5-7be8396a97d8",
   "metadata": {},
   "source": [
    "Select 10 random words from corpus and encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a411c294-f9fe-42ab-971d-561ddd432360",
   "metadata": {},
   "outputs": [],
   "source": [
    "roles_to_corpus = {}\n",
    "for role in string.ascii_lowercase[:10]:\n",
    "    roles_to_corpus[role] = np.array([mapping[letter] for letter in random.choice(corpus)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91ad25-13f0-47e9-8715-0794baa4ee70",
   "metadata": {},
   "source": [
    "Create training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b3e4a-88d4-4057-8a7b-da231c782301",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X.shape=\", X.shape)\n",
    "print(\"Y.shape=\", Y.shape)\n",
    "print(\"preY.shape=\", preY.shape)\n",
    "print(\"postY.shape=\", postY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947d7af8-f044-4e63-8d66-47fb199a44df",
   "metadata": {},
   "source": [
    "# Make transformer blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043fbb4-96c3-439f-b281-6b0237c487b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                   key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate \n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_heads': self.num_heads, 'embed_dim': self.embed_dim,\n",
    "            'ff_dim': self.ff_dim, 'rate': self.rate\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd35315-bd05-4e35-8517-d8565270cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedTransformerBlock(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(MaskedTransformerBlock, self).__init__()\n",
    "        self.att1 = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                    key_dim=embed_dim)\n",
    "        self.att2 = keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                    key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [keras.layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "             keras.layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate \n",
    "        \n",
    "    def causal_attention_mask(self, batch_size, n_dest, n_src, dtype):\n",
    "        \"\"\"Masks the upper half of the dot product matrix in self attention.\n",
    "        This prevents flow of information from future tokens to current token.\n",
    "        1's in the lower triangle, counting from the lower right corner.\n",
    "        \"\"\"\n",
    "        i = tf.range(n_dest)[:, None]\n",
    "        j = tf.range(n_src)\n",
    "        m = i >= j - n_src + n_dest\n",
    "        mask = tf.cast(m, dtype)\n",
    "        mask = tf.reshape(mask, [1, n_dest, n_src])\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        input_shape = tf.shape(inputs[0])\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "        mask = self.causal_attention_mask(batch_size,\n",
    "                                         seq_len, seq_len,\n",
    "                                         tf.bool)\n",
    "        # mask = tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        attn_output1 = self.att1(inputs[0], inputs[0],\n",
    "                                 attention_mask = mask)\n",
    "        attn_output1 = self.dropout1(attn_output1, training=training)\n",
    "        out1 = self.layernorm1(inputs[0] + attn_output1)\n",
    "        attn_output2 = self.att2(out1, inputs[1])\n",
    "        attn_output2 = self.dropout2(attn_output2, training=training)\n",
    "        out2 = self.layernorm1(out1 + attn_output2)\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        return self.layernorm2(out2 + ffn_output)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'num_heads': self.num_heads, 'embed_dim': self.embed_dim,\n",
    "            'ff_dim': self.ff_dim, 'rate': self.rate\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a9ad8b-133e-4cfe-8091-650c6e240d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self,maxlen,embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen,\n",
    "                                              output_dim=embed_dim)\n",
    "        self.maxlen = maxlen\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "    def call(self,x):\n",
    "        maxlen = tf.shape(x)[1]\n",
    "        print(maxlen)\n",
    "        positions = tf.range(start=0,limit=maxlen,delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        print(tf.shape(positions))\n",
    "        print(tf.shape(x))\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'maxlen': self.maxlen,\n",
    "            'embed_dim': self.embed_dim \n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f379362-35fe-4795-91d4-c8e3fa9b6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def MaskedSparseCategoricalCrossentropy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def MaskedSparseCategoricalAccuracy(real, pred):\n",
    "    accuracies = tf.equal(tf.cast(real,tf.int64), tf.argmax(pred, axis=2))\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    accuracies = tf.math.logical_and(mask, accuracies)\n",
    "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "    mask = tf.cast(mask, dtype=tf.float32)\n",
    "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2dc23-88f1-4c7c-a6a7-34f307b23c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedTokenAndPositionEmbedding(keras.layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(MaskedTokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = keras.layers.Embedding(input_dim=vocab_size,\n",
    "                                                output_dim=embed_dim,\n",
    "                                                mask_zero=True)\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen+1,\n",
    "                                              output_dim=embed_dim,\n",
    "                                              mask_zero=True)\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=1, limit=maxlen+1, delta=1)\n",
    "        positions = positions * tf.cast(tf.sign(x),tf.int32)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'maxlen': self.maxlen,\n",
    "            'vocab_size': self.vocab_size,\n",
    "            'embed_dim': self.embed_dim\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24300dde-cbee-49ee-8776-75873aa08114",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b386e14-0a81-4d72-b4c3-2ee1f9174dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the gestalt, context representations...\n",
    "input_length  = 5+1 # Length of each word?\n",
    "output_length = 5+1 # Length of word plus start/stop?\n",
    "\n",
    "HIDDEN_SIZE = 1024 # 1024 in Blake's\n",
    "BATCH_SIZE  = 100\n",
    "EPOCHS      = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb776d-f16a-44f8-89c6-56fc3c2e7662",
   "metadata": {},
   "source": [
    "# Create encoder/decoder \n",
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115ab18-77a2-4e2c-ae21-443ee87ec08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 300  # Embedding size for each token (orig. 32)\n",
    "num_heads = 4  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer (orig. 32)\n",
    "stack = 1\n",
    "wd = 0.01\n",
    "\n",
    "# Make the layers\n",
    "encoder_input = keras.layers.Input(shape=(None,)) # Orig. (None,)\n",
    "\n",
    "# encoder_embedding = keras.layers.Embedding(\n",
    "#                     input_dim=len(mapping), output_dim=embed_dim)(encoder_input)\n",
    "\n",
    "# encoder_pos_embedding = PositionEmbedding(\n",
    "#                         maxlen=input_length,\n",
    "#                         embed_dim=embed_dim)(encoder_embedding)\n",
    "\n",
    "encoder_embedding = MaskedTokenAndPositionEmbedding(maxlen = input_length, vocab_size = len(mapping), embed_dim = embed_dim)(encoder_input)\n",
    "\n",
    "model = keras.Model(encoder_input, encoder_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2575e15b-40d5-49c7-aa25-93f8c15ed5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encoder_embedding\n",
    "for _ in range(stack):\n",
    "    x = TransformerBlock(embed_dim=embed_dim,\n",
    "                         num_heads=num_heads,\n",
    "                         ff_dim=ff_dim)(x)\n",
    "encoder_state = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e304b7c-ca9d-468a-b2a8-2631e48cf382",
   "metadata": {},
   "source": [
    "Decoder Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848340f5-a557-4d9b-b506-8fa014ad21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder blocks, using `encoder_state` as initial state.\n",
    "decoder_input = keras.layers.Input(shape=(None,)) # Orig. (None,)\n",
    "\n",
    "# decoder_embedding = keras.layers.Embedding(\n",
    "#                     input_dim=len(mapping), output_dim=embed_dim)(decoder_input)\n",
    "\n",
    "# decoder_pos_embedding = PositionEmbedding(\n",
    "#                         maxlen=output_length,\n",
    "#                         embed_dim=embed_dim)(decoder_embedding)\n",
    "    \n",
    "    \n",
    "decoder_embedding = MaskedTokenAndPositionEmbedding(maxlen = output_length, vocab_size = len(mapping), embed_dim = embed_dim)(decoder_input)\n",
    "\n",
    "x = decoder_embedding\n",
    "decoder_blocks = []\n",
    "for _ in range(stack):\n",
    "    decoder_blocks += [MaskedTransformerBlock(embed_dim=embed_dim,\n",
    "                                                  num_heads=num_heads,\n",
    "                                                  ff_dim=ff_dim)]\n",
    "    x = decoder_blocks[-1]([x,encoder_state])\n",
    "\n",
    "decoder_dense = keras.layers.Dense(decoder_vocab_size,\n",
    "                                       activation='softmax') # Orig. decoder vocab size\n",
    "decoder_output = decoder_dense(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead4815-89a3-46df-a3eb-d1163dda1b76",
   "metadata": {},
   "source": [
    "Assemble model and compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb02aa-e814-4135-bead-e13313d6a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model([encoder_input, decoder_input],\n",
    "                         decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d825e-d1ac-428f-ab2b-12145fad0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=MaskedSparseCategoricalCrossentropy,\n",
    "                  optimizer=tfa.optimizers.AdamW(weight_decay=wd,learning_rate=.001), #.0001\n",
    "                  metrics=[MaskedSparseCategoricalAccuracy])\n",
    "model.summary()\n",
    "    \n",
    "# Visualization - wish we could see the recurrent weights!\n",
    "keras.utils.plot_model(model,to_file='EncTransformDec.png',\n",
    "                       show_shapes=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428352f1-74a8-4175-94d7-afbdc79d583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([X,preY], postY,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS,\n",
    "              verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a23d120-979e-4c8d-8ddc-18c74f9d15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',model.evaluate([X,preY],postY)[1]*100.0,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d1df1-421f-4ef9-a2a8-1e6a1790ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "# summarize history for accuracy \n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['MaskedSparseCategoricalAccuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "# summarize history for loss  \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33bc99-b091-4014-9b76-8978852baec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make just a model out of the encoder\n",
    "# input = encoder_input (Input layer)\n",
    "# output = encoder_states (enc Hidden layer * 2)\n",
    "encoder_model = keras.Model(encoder_input, encoder_state)\n",
    "\n",
    "# Part 2 - make the decoder\n",
    "\n",
    "# Make just a model out of the decoder\n",
    "x = decoder_embedding\n",
    "encoder_state_input = keras.layers.Input(shape=(None,embed_dim))\n",
    "for i in range(stack):\n",
    "    x = decoder_blocks[i]([x,encoder_state_input])\n",
    "decoder_output = decoder_dense(x)\n",
    "decoder_model = keras.Model([decoder_input, encoder_state_input],\n",
    "                             decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0681a-2301-4405-9a91-5e293a1f00b1",
   "metadata": {},
   "source": [
    "# try to pass things through the outer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4444da-869a-46b0-9d3f-475f3ac4389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated Decoder Model\n",
    "keras.utils.plot_model(decoder_model,\n",
    "                       show_shapes=True,expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e3d0f1-7a70-46cd-9b54-889b1acc99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with teacher forcing\n",
    "i = 0 \n",
    "context = encoder_model.predict(X[i:i+1])\n",
    "context.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d8b84-6ed8-4aeb-add7-bb5caff46da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.argmax(decoder_model.predict([preY[i:i+1,:],context]),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547474a-a3db-40ff-828e-151a81a9914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff15e9-4274-4b4f-8f40-13b4a080860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decodeseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da241a1b-33ee-4885-adbc-840ed5e31e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without teacher forcing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274f157-8e11-480d-bf07-934b558c3f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = preY[0:1,0:1]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64d8d5-32dc-456e-9eb0-e0da787ae4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = encoder_model.predict(X[i:i+1])\n",
    "result = np.zeros_like(preY[i:i+1])\n",
    "result[0:1,0:1] = preY[i:i+1,0:1] # Start only...\n",
    "for j in range(output_length): #ouput length is 5+1 \n",
    "    tokens = np.argmax(decoder_model.predict([result,context]),-1)\n",
    "    result[0:1,j+1:j+2] = tokens[0:1, j:j+1]\n",
    "result = tokens # Remove start token\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbd2123-c066-4673-8ec4-0d667c5e62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "context.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987014d7-0da1-4397-a51f-ed377db19fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "preY[i:i+1,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cd1020-b08f-4aed-90ee-f54d32de9a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "context = encoder_model.predict(X[i:i+3])\n",
    "result = np.zeros_like(preY[i:i+3])\n",
    "result[:,0:1] = preY[i:i+3,0:1] # Start only...\n",
    "for j in range(output_length): #ouput length is 5+1 \n",
    "    tokens = np.argmax(decoder_model.predict([result,context]),-1)\n",
    "    result[:,j+1:j+2] = tokens[:, j:j+1]\n",
    "result = tokens # Remove start token\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318989a-070d-4443-a429-6e7b64b2e027",
   "metadata": {},
   "outputs": [],
   "source": [
    "postY[i:i+3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d062f4dc-7bb8-40c8-9498-dcbcf0cc36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doesn't work \n",
    "context = encoder_model.predict(X[i:i+1])\n",
    "result = preY[0:1,0:1] # Start only...\n",
    "for i in range(output_length):\n",
    "    tokens = np.argmax(decoder_model.predict([result,context]),-1)\n",
    "    result = np.hstack([result,tokens[:,-1:]])\n",
    "result = np.int32(result[:,1:]) # Remove start token\n",
    "print(result[0])\n",
    "#decode_seq(result[0],itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a06af-621f-4bde-9c6e-ba47ac347885",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc9d47-a5f7-4098-a4ca-bb0f030c07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "postY[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b01e3-7cbd-4e7a-9fba-21b612bdeb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([X[i:i+1], preY[i:i+1]]).argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec12fe-7c3d-4e25-b745-f2e31135b71a",
   "metadata": {},
   "source": [
    "# Export Model (commented out so it doesn't make a new one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68173c06-b22e-4910-bce3-27f952661dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (True):\n",
    "#     encoder_model_json = encoder_model.to_json()\n",
    "#     decoder_model_json = decoder_model.to_json()\n",
    "#     with open(\"models/encoder_len53.json\", \"w\") as encoder_file, open(\"models/decoder_len53.json\", \"w\") as decoder_file:\n",
    "#         encoder_file.write(encoder_model_json)\n",
    "#         decoder_file.write(decoder_model_json)\n",
    "#     encoder_model.save_weights(\"models/encoder_len53.h5\")\n",
    "#     decoder_model.save_weights(\"models/decoder_len53.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9684b-c1b4-4cb5-957f-33f9a8df51be",
   "metadata": {},
   "source": [
    "# Try to link it with the nested enc dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7572a3-3d3c-47ce-832f-eff9cae9b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b83252-1e80-40c7-b742-2ed9021f103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_encoder = encoder_model\n",
    "outer_decoder = decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98998ae9-eeab-419f-b207-6fc7fdc5840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(outer_encoder, show_shapes=True)\n",
    "keras.utils.plot_model(outer_decoder, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704de3ab-0f0b-4be3-b0e0-ed01423d5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01cb8c-0997-45de-bd0a-6fec2145869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp,_,_,_,_ = letter_to_int(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71137dc7-7d31-4b15-bb12-2e82e382c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d54cb-ebd2-4096-a20f-a250004e322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[x for x in temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bd8ea-10ce-4eeb-a321-01b30535067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607c586-5ed9-4d2c-93d3-4e945bd803e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 10 indices from the coprus WOR\n",
    "corIdx = np.random.randint(0,high=len(corpus),size=20)\n",
    "#I could probably just do a np array of size 10000 \n",
    "corIdx = np.random.choice(corIdx,size=10,replace=False)\n",
    "\n",
    "outer_x = X[corIdx]\n",
    "outer_preY = preY[corIdx]\n",
    "outer_postY = postY[corIdx]\n",
    "\n",
    "outer_embeddings = outer_encoder.predict(outer_x)\n",
    "\n",
    "trainingSet_int = letter_to_int(trainingSet)[0]\n",
    "\n",
    "inner_x = np.array([outer_embeddings[trainingSet_int[x]-1] for x in range(len(trainingSet))]) #200 comes from the trainingSet \n",
    "\n",
    "dog = np.zeros((1,5,300))\n",
    "dog.shape\n",
    "np.concatenate((dog, inner_x[0]))\n",
    "\n",
    "#make inner_postY and outer_postY\n",
    "dog = np.zeros((1,5,300))\n",
    "inner_preY = np.array([np.concatenate((dog,inner_x[i])) for i in range(len(inner_x))])\n",
    "inner_postY = np.array([np.concatenate((inner_x[i],dog)) for i in range(len(inner_x))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b0cb-185b-4fba-bd30-fe4120134e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[corIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2282e8-f9a7-49a5-a42f-5581b23dd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453846f-c3e1-40a8-a8cd-7c9f8178627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet_int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a11539-41fb-41de-9a6e-c864f2b78c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86262c85-d693-46b4-babb-f32d48d46ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c512b-87a8-4a06-8c52-9d2f3f865075",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_x[trainingSet_int[0]-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b035af-123f-4282-b7e3-ce1a3275066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[9676]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba806e3-d001-4b8a-acac-538e6506e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1887f5-da3d-46fb-9148-5ad9f0ac2c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8d3989-3d25-4075-8391-bd3d932b2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44e6744-e848-4dd1-b077-f09c952c0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ec9728-e9d2-4954-a081-1ef2c41aabba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner encoder construction \n",
    "hidden_size = 300\n",
    "inner_encoder_input = keras.layers.Input(shape=(None,) + inner_x.shape[2:], name=\"inner_encoder_input\")\n",
    "#reshape layer here\n",
    "inner_encoder_reshape = keras.layers.Reshape((-1,1500))(inner_encoder_input)\n",
    "inner_encoder_hidden = keras.layers.LSTM(hidden_size, return_state=True, name=\"inner_encoder\") #pass layers in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cce34-764c-477f-b5eb-c615eca4dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_output, enc_state_h, enc_state_c = inner_encoder_hidden(inner_encoder_reshape)\n",
    "encoder_states = [enc_state_h, enc_state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f04b0-d70f-46f2-b8e8-f680c176c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_preY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f5695-82c7-40c6-b209-684a04dfa1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner decoder construction\n",
    "inner_decoder_input_1 = keras.layers.Input(shape=(None,) + inner_preY.shape[2:], name=\"inner_dec_token_1\")\n",
    "inner_decoder_reshape = keras.layers.Reshape((-1,1500))(inner_decoder_input_1)\n",
    "inner_decoder_input_2 = keras.layers.Input(shape=(None, 2), name=\"dec_start/stop\")\n",
    "inner_decoder_concat = keras.layers.Concatenate()([inner_decoder_reshape,inner_decoder_input_2])\n",
    "\n",
    "inner_decoder_hidden = keras.layers.LSTM(hidden_size,return_sequences=True,return_state=True,name=\"inner_decoder\") #need initial state for h and c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8a7e45-1c9e-44f8-9c84-a377fd23d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tie it together \n",
    "decoder_hidden_output, decoder_state_h, decoder_state_c = inner_decoder_hidden(inner_decoder_concat,\n",
    "                                                                         initial_state=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38327d03-08b0-4795-aa98-13aa688365db",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_postY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e9caf-dbfb-47b2-836e-dfb003539edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense_t1 = keras.layers.Dense(inner_encoder_reshape.shape[-1], activation='linear', name=\"token_1\")(decoder_hidden_output)\n",
    "inner_output_reshape = keras.layers.Reshape((-1,inner_postY.shape[2],inner_postY.shape[3]))(decoder_dense_t1)\n",
    "decoder_dense_t2 = keras.layers.Dense(2, activation='sigmoid', name=\"start/stop\")(decoder_hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e77633-df48-441e-8c3f-3987544c1bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_decoder_output = [inner_output_reshape, decoder_dense_t2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3646e9-2f99-48c1-b150-4049a14dfb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model = keras.Model([inner_encoder_input,inner_decoder_input_1, inner_decoder_input_2],\n",
    "                         inner_decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d783b8d2-e9d7-42c4-ad9b-50eef20f30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the pre start/stop which will have dimensions (200,4,2)\n",
    "#pre_start = np.array([[1,0,0,0] for x in range(0,200)])\n",
    "#is it just the exact same as Blake's\n",
    "s_s = {\"start\":[1,0],\"stop\":[0,1], \"none\":[0,0]}\n",
    "pre_start = np.zeros((inner_x.shape[0], 4, 2))\n",
    "post_stop = np.zeros((inner_x.shape[0], 4, 2))\n",
    "pre_start[:,0,:] = s_s[\"start\"]\n",
    "post_stop[:,3,:] = s_s[\"stop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3fbe2-8570-48f9-b92a-2f7cdfcf16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd872f7-8d80-4df9-8f69-ec1a25d87f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model.compile(loss = [keras.losses.MSE,keras.losses.binary_crossentropy],\n",
    "               optimizer=keras.optimizers.Nadam(),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b614839-e961-4017-9ee0-464d5d02025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner_model_input = {\"inner_encoder_input\":inner_x,\"inner_enc_token_1\":inner_preY,3                     \"dec_start/stop\":pre_start}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ba969-9872-41e7-a786-c09f0cd1b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model_input = {\"input_1\":inner_x,\"input_2\":inner_preY,\n",
    "                     \"dec_start/stop\":pre_start}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548fd5f-1925-4d06-b8f2-342158901f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_model_target = {\"inner_dec_token_1\":inner_postY,\"start/stop\": post_stop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658f7c3-dd20-4d3a-bc45-4cc3bc02656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2ee027-d797-4ad1-a42f-a69294a048cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(inner_model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87483623-7fd5-4bf3-9041-9d932ec470c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to train it \n",
    "inner_batch_size = 25\n",
    "inner_epochs = 40\n",
    "inner_history = inner_model.fit([inner_x,inner_preY, pre_start], [inner_postY,post_stop],\n",
    "                         batch_size=inner_batch_size,\n",
    "                         epochs=inner_epochs,\n",
    "                         verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59d993-0a54-4aff-a77a-73ee7c0e5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d402a-780e-40ee-92dc-9659fe9e284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "# summarize history for accuracy \n",
    "plt.subplot(211)  \n",
    "plt.plot(inner_history.history['reshape_2_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('reshape_2_accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "# summarize history for loss  \n",
    "plt.subplot(212)  \n",
    "plt.plot(inner_history.history['loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a42e37c-8785-4e0d-8a46-d4e1bb465367",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = inner_model.evaluate([inner_x,inner_preY, pre_start], [inner_postY,post_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd101d9-aa8d-4e03-9107-e9c9c7e39b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner_model.predict([inner_x[0:1],inner_preY[0:1],pre_start[0:1]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f1706e-6a36-471f-909b-176e97930cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner_postY[0:1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdce7cb-c64b-4349-a8ef-cfe87efde93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.sum(keras.losses.MSE(y_pred=inner_model.predict([inner_x[0:1],inner_preY[0:1],pre_start[0:1]])[0], y_true= inner_postY[0:1] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435d22e-0675-4eb4-8c52-c6eba6fb1d8d",
   "metadata": {},
   "source": [
    "# Remove teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189aca50-0c85-4999-a4f5-7dd7276089ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder \n",
    "inner_encoder_model = keras.Model(inner_encoder_input, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a045a05-420e-4782-9f9f-d3bfb77fe3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(inner_encoder_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353d2a2d-3d68-4007-9884-534d22dc7a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder \n",
    "inner_decoder_state_input_h = keras.layers.Input(shape=(hidden_size,),\n",
    "                                                name='inner_states_input_h')\n",
    "\n",
    "inner_decoder_state_input_c = keras.layers.Input(shape=(hidden_size,),\n",
    "                                                name='inner_states_input_c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7840d2ae-3c2d-4dd9-a852-adcb867ddde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect hidden to input(s)\n",
    "inner_decoder_states_input = [inner_decoder_state_input_h,\n",
    "                             inner_decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6b8b0-a831-4047-9c4f-e8ad26e2c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_decoder_hidden_output, inner_decoder_state_h, inner_decoder_state_c = inner_decoder_hidden(inner_decoder_concat,\n",
    "              initial_state=inner_decoder_states_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4bac0-a1de-4e00-813f-04d6fd9325cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_decoder_hidden_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8578d4e-a6ee-4263-b847-124869f56dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_decoder_states = [inner_decoder_state_h, inner_decoder_state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998b6e53-5ec4-42c6-bdef-2ed26bc255fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_decoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5331e2b-e5de-4154-babc-7c5223730794",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense_t1 = keras.layers.Dense(inner_encoder_reshape.shape[-1], activation='linear', name=\"token_1\")\n",
    "#inner_output_reshape = keras.layers.Reshape((-1,inner_postY.shape[2],inner_postY.shape[3]))(decoder_dense_t1)\n",
    "decoder_dense_t2 = keras.layers.Dense(2, activation='sigmoid', name=\"start/stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52e9e1-b025-4272-bdea-e8016f290f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_output_reshape_2 = keras.layers.Reshape((-1,inner_postY.shape[2],inner_postY.shape[3]))(decoder_dense_t1(inner_decoder_hidden_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5233ba-6362-45b9-afe7-e9f226296295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect output to hidden(s)\n",
    "inner_decoder_output = [inner_output_reshape_2, decoder_dense_t2(inner_decoder_hidden_output)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd87f8b-d0db-46cf-b45b-020f065d0947",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_decoder_output + inner_decoder_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a122324a-fadf-4cf7-9c18-aa50f0ee74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to fix\n",
    "inner_decoder_model = keras.Model([inner_decoder_input_1, inner_decoder_input_2] + inner_decoder_states_input,\n",
    "                                 inner_decoder_output + inner_decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48edb999-f5e0-4174-a555-b202f3c402e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(inner_decoder_model,to_file=\"decouple_inner_model.png\",show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc65a6-156f-4d16-a2bf-2bb7ad1658cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = inner_encoder_model.predict(inner_x[0:1])\n",
    "embedding[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92807b4f-02fc-444c-8dfc-41b4fc21f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_preY[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddee7f3-3f96-41c0-99dc-c835efa998b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "teachOut = inner_decoder_model.predict([inner_preY[0:1], pre_start[0:1]] + embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2702fdb7-17d9-4c2e-a8ce-59ab59d6badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "teachOut[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d49bab-b367-4ff2-9f98-df6717aeff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stop[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948af672-a8fc-4935-a354-d1dd142a97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "teachOut[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e46fe-4d7b-46dd-aa1e-aaacaf8f3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_postY[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8076b-88f2-4678-98c5-cb0685f16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without teacher forcing \n",
    "input_tokens = np.zeros_like(inner_preY[0:1])\n",
    "input_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd44f9b-db78-4c8e-a9ff-b64ea5482190",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = inner_decoder_model.predict([input_tokens, pre_start[0:1]] + embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51df3e-0340-4872-9421-8abf87518b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53ea53-4604-4cd1-83ed-b00d41bf308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens[0][:,0:1,:,:].shape #replace on input_tokens timestep one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4454ae8-303d-4f1c-9328-b4e1fe661860",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens[:,1:2,:,:] = output_tokens[0][:,0:1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eeba99-d524-49e2-8828-93aba870115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = inner_decoder_model.predict([input_tokens, pre_start[0:1]] + embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df782ab0-4b3a-4724-bac8-45b32216cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the context\n",
    "embedding = inner_encoder_model.predict(inner_x[0:1]) \n",
    "#without teacher forcing\n",
    "\n",
    "input_tokens = np.zeros_like(inner_preY[0:1])\n",
    "\n",
    "input_start = np.zeros_like(pre_start[0:1])\n",
    "\n",
    "input_start[0,0:1,:] = pre_start[0,0:1,:]\n",
    "\n",
    "for i in range(0,3):\n",
    "    output_tokens = inner_decoder_model.predict([input_tokens, input_start] + embedding)\n",
    "    \n",
    "    input_tokens[:,i+1:i+2,:,:] = output_tokens[0][:,i:i+1,:,:] #replace on input_tokens timestep\n",
    "    input_start[:,i+1:i+2,:] = output_tokens[1][:,i:i+1,:]\n",
    "    embedding = output_tokens[2:4]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae403ac-13fe-4056-ac62-f87ef5c04dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with teacher forcing \n",
    "#output_tokens = inner_model.predict([inner_x[0:1], inner_preY[0:1], pre_start[0:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc356a-3416-4781-b25f-6f3efe5a5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make just a model out of the decoder\n",
    "\"\"\"\n",
    "x = decoder_embedding\n",
    "encoder_state_input = keras.layers.Input(shape=(None,embed_dim))\n",
    "for i in range(stack):\n",
    "    x = decoder_blocks[i]([x,encoder_state_input])\n",
    "decoder_output = decoder_dense(x)\n",
    "decoder_model = keras.Model([decoder_input, encoder_state_input],\n",
    "                             decoder_output)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf3a289-2cbd-4403-a5e5-4cd3def28842",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c09e5eb-56ee-4697-8ebe-761de77561dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192a693-e1ae-4971-ade8-23a16e596165",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(decoder_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca03c0-0797-4d08-b4d5-fdb863842b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b7c86-84d4-479f-ae37-0eb749f755dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pre_start[0:1] #start \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0698a3f-542c-4790-b273-81c0610ea2ee",
   "metadata": {},
   "source": [
    "# Plug inner decoder's output into outer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8d3ba-2ad7-4c76-863f-3c332862c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens = [inner_postY[0:1], post_stop[0:1]]\n",
    "\n",
    "for k in range(0,3):\n",
    "    context = output_tokens[0][0][k:k+1,:,:]\n",
    "    i=0\n",
    "    result = np.zeros_like(preY[i:i+1])\n",
    "    result[0:1,0:1] = preY[i:i+1,0:1] # Start only...\n",
    "\n",
    "    for j in range(output_length): #ouput length is 5+1 \n",
    "        tokens = np.argmax(outer_decoder.predict([result,context]),-1)\n",
    "        result[0:1,j+1:j+2] = tokens[0:1, j:j+1]\n",
    "    result = tokens # Remove start token\n",
    "    print(int_to_letter(result, mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed8eb4-000d-4f0b-812d-525677644476",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_letter(outer_x[trainingSet_int[0]-1], mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bb5d2-9b6b-46ae-acb1-d4af408bcebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70656b-d7d2-4a1f-8566-5c6b9d833039",
   "metadata": {},
   "outputs": [],
   "source": [
    "corIdx[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d232ce-390d-4f63-b277-3d93877c7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[corIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1dcc6d-3e1c-46ee-9907-32881897dbed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929c14b4-2bf9-4866-8826-e2629bb27454",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_postY[trainingSet_int[0]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0031a9b-533f-4cc3-9714-04f673211b03",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Check the ouput against postY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba574a9a-d327-407c-9244-f829c629363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_x[0:1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b0c4f-c7b0-4796-9f2d-a6ed683d723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_postY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0babb30f-eab2-47fb-af9f-87427a582d84",
   "metadata": {},
   "source": [
    "do this three times in a loop and ouput is the non teacher foced input, generate out put tokens then output tokens need to be passed into the\n",
    "outer decoder. take the (5,300) input and then feed it in one at a time non-teacher forced (provide as the embedding for the outer). We need to unfold for the 6 timesteps. produce at the end 6 integers. Use MSE and binary cross entropy for stiched together inner model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42974b71-2dd0-441f-8d07-708144b49a85",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a2c9d5-bd37-4f54-8e8c-9c2b72df4ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f448d-d36e-4955-af46-d0b6fd318b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8939134-bffd-4947-b599-fcc2ff9f3eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
